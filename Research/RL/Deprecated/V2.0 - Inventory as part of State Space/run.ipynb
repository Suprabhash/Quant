{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.rcParams['axes.grid'] = False\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Adam' from 'keras.optimizers' (c:\\users\\suprabhashsahu\\desktop\\strategyresearch\\venv\\lib\\site-packages\\keras\\optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01menvs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TradingEnv\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01magent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DQNAgent\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_data, get_scaler, maybe_make_dir\n",
      "File \u001B[1;32m~\\Desktop\\StrategyResearch\\RL\\V2.0 - Inventory as part of State Space\\agent.py:4\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mlp\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mDQNAgent\u001B[39;00m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[0;32m      9\u001B[0m   \u001B[38;5;124;03m\"\"\" A simple Deep Q agent \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\StrategyResearch\\RL\\V2.0 - Inventory as part of State Space\\model.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmlp\u001B[39m(n_obs, n_action, n_hidden_layer\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, n_neuron_per_layer\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m,\n\u001B[0;32m      8\u001B[0m         activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      9\u001B[0m   \u001B[38;5;124;03m\"\"\" A multi-layer perceptron \"\"\"\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'Adam' from 'keras.optimizers' (c:\\users\\suprabhashsahu\\desktop\\strategyresearch\\venv\\lib\\site-packages\\keras\\optimizers.py)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from envs import TradingEnv\n",
    "from agent import DQNAgent\n",
    "from utils import get_data, get_scaler, maybe_make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('-e', '--episode', type=int, default=2000,\n",
    "                      help='number of episode to run')\n",
    "  parser.add_argument('-b', '--batch_size', type=int, default=32,\n",
    "                      help='batch size for experience replay')\n",
    "  parser.add_argument('-i', '--initial_invest', type=int, default=20000,\n",
    "                      help='initial investment amount')\n",
    "  parser.add_argument('-m', '--mode', type=str, required=True,\n",
    "                      help='either \"train\" or \"test\"')\n",
    "  parser.add_argument('-w', '--weights', type=str, help='a trained model weights')\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  maybe_make_dir('weights')\n",
    "  maybe_make_dir('portfolio_val')\n",
    "\n",
    "  timestamp = time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "  data = np.around(get_data())\n",
    "  train_data = data[:, :3526]\n",
    "  test_data = data[:, 3526:]\n",
    "\n",
    "  env = TradingEnv(train_data, args.initial_invest)\n",
    "  state_size = env.observation_space.shape\n",
    "  action_size = env.action_space.n\n",
    "  agent = DQNAgent(state_size, action_size)\n",
    "  scaler = get_scaler(env)\n",
    "\n",
    "  portfolio_value = []\n",
    "\n",
    "  if args.mode == 'test':\n",
    "    # remake the env with test data\n",
    "    env = TradingEnv(test_data, args.initial_invest)\n",
    "    # load trained weights\n",
    "    agent.load(args.weights)\n",
    "    # when test, the timestamp is same as time when weights was trained\n",
    "    timestamp = re.findall(r'\\d{12}', args.weights)[0]\n",
    "\n",
    "  for e in range(args.episode):\n",
    "    state = env.reset()\n",
    "    state = scaler.transform([state])\n",
    "    for time in range(env.n_step):\n",
    "      action = agent.act(state)\n",
    "      next_state, reward, done, info = env.step(action)\n",
    "      next_state = scaler.transform([next_state])\n",
    "      if args.mode == 'train':\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "      state = next_state\n",
    "      if done:\n",
    "        print(\"episode: {}/{}, episode end value: {}\".format(\n",
    "          e + 1, args.episode, info['cur_val']))\n",
    "        portfolio_value.append(info['cur_val']) # append episode end portfolio value\n",
    "        break\n",
    "      if args.mode == 'train' and len(agent.memory) > args.batch_size:\n",
    "        agent.replay(args.batch_size)\n",
    "    if args.mode == 'train' and (e + 1) % 10 == 0:  # checkpoint weights\n",
    "      agent.save('weights/{}-dqn.h5'.format(timestamp))\n",
    "\n",
    "  # save portfolio value history to disk\n",
    "  with open('portfolio_val/{}-{}.p'.format(timestamp, args.mode), 'wb') as fp:\n",
    "    pickle.dump(portfolio_value, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}