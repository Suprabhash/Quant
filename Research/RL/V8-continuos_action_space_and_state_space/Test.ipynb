{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.rcParams['axes.grid'] = False\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from V8Suprabhash import get_stock_data, add_features,  plot_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Dense\n",
    "########################## Changes made here ##################################\n",
    "def get_model(num_features, num_actions, num_dense_layers, neurons_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(batch_input_shape=(1, num_features+num_actions)))\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(num_actions, activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "###############################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "features = [\n",
    "    {\"feature\": \"Close_as_a_feature\", \"lookback\": 0},\n",
    "    {\"feature\": \"diff_of_close\", \"lookback\": 1},\n",
    "]\n",
    "\n",
    "#Experiment params\n",
    "ticker = 'sinx'#'NIFc1'\n",
    "tune = False\n",
    "train_percent = 0.8\n",
    "state_lookback = 1\n",
    "num_dense_layers = 2\n",
    "num_dense_layers_by_num_features = 2\n",
    "alpha = 0.5\n",
    "epsilon = 0.1\n",
    "gamma = 0.1\n",
    "episodes = 100\n",
    "metric = \"percent\"\n",
    "\n",
    "############################################################################################################################################\n",
    "\n",
    "#Get data\n",
    "df = get_stock_data(ticker)\n",
    "df = add_features(df, features, state_lookback, 0.8)\n",
    "train_df = df.iloc[:int(0.8 * len(df)), :]\n",
    "test_df = df.iloc[int(0.8 * len(df)):, :]\n",
    "\n",
    "\n",
    "########################## Changes made here ##################################\n",
    "all_actions = {0: 'percentage_invested_in_equity'}\n",
    "###############################################################################\n",
    "\n",
    "model = get_model(len(features)*state_lookback, len(all_actions), num_dense_layers, len(features)*state_lookback*num_dense_layers_by_num_features)\n",
    "# visualizer(model, format='png', view=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_q_learning(train, state_lookback, model, alpha, epsilon, gamma, episodes, all_actions, metric, features, number_of_random_samples, plot=True):\n",
    "\n",
    "    train_data = train.copy()\n",
    "    returns_vs_episodes = []\n",
    "    best_episode_return = 0\n",
    "    weights_best_performing = None\n",
    "\n",
    "    arr = np.empty(shape=(0,len(features)*state_lookback+len(all_actions)))\n",
    "    arr1 = train_data[[feature['feature'] for feature in features] + [f\"{col}_shift{i}\" for col in [feature['feature'] for feature in features] for i in range(1, state_lookback)]].values\n",
    "    for i in range(len(arr1)):\n",
    "        random_actions = np.random.uniform(0,1,number_of_random_samples)\n",
    "        for j in range(number_of_random_samples):\n",
    "            arr = np.vstack((arr,np.r_[arr1[i], random_actions[j]]))\n",
    "\n",
    "    for ii in tqdm(range(episodes)):\n",
    "\n",
    "        #Backtester initialisation\n",
    "        balance = 10000\n",
    "        net_worth = balance\n",
    "        in_position = False\n",
    "        number_of_units_in_position = 0\n",
    "        position_value = 0.0\n",
    "        actions_history = []\n",
    "        equity_curve = []\n",
    "        rewards = []\n",
    "        states = []\n",
    "        prices = []\n",
    "        current_q_all_states = []\n",
    "        next_q_all_states = []\n",
    "\n",
    "        q = model.predict(arr)\n",
    "        current_qs = []\n",
    "        next_qs = []\n",
    "        actions = []\n",
    "        for i in range(len(arr1)):\n",
    "            q_list = []\n",
    "            next_q_list = []\n",
    "            for j in range(number_of_random_samples):\n",
    "                q_list.append(q[i*number_of_random_samples+j])\n",
    "            for j in range(number_of_random_samples):\n",
    "                next_q_list.append(q[(i+1)*number_of_random_samples+j])\n",
    "            next_qs.append(max(next_q_list))\n",
    "            current_qs.append(max(q_list))\n",
    "            actions.append(arr[q_list.index(max(q_list))][-1])\n",
    "\n",
    "        current_qs = current_qs.reshape(-1,1)\n",
    "        next_qs = next_qs.reshape(-1,1)\n",
    "        actions = actions.reshape(-1,1)\n",
    "\n",
    "        for i in range(1,len(train_data)):\n",
    "            current_adj_close = train_data.iloc[i][\"Close\"]\n",
    "            last_day_adj_close = train_data.iloc[i - 1][\"Close\"]\n",
    "            prices.append(current_adj_close)\n",
    "            states.append(arr[i])\n",
    "            current_q_all_states.append(current_qs[i][0])\n",
    "\n",
    "            # decide action\n",
    "            if epsilon > 0.1:\n",
    "                epsilon = epsilon / 1.2\n",
    "\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action = np.random.uniform(0,1)\n",
    "            else:\n",
    "                action= actions[i][0]\n",
    "\n",
    "            actions_history.append(action)\n",
    "\n",
    "            if not in_position:\n",
    "                if action == 1:  # OPEN LONG\n",
    "                    in_position = True\n",
    "                    number_of_units_in_position = balance/current_adj_close\n",
    "                    balance = balance - (number_of_units_in_position*current_adj_close)\n",
    "                    position_value = number_of_units_in_position*current_adj_close\n",
    "                    net_worth = balance + position_value\n",
    "                    equity_curve.append(net_worth)\n",
    "                    rewards.append(0)\n",
    "                else:\n",
    "                    net_worth = balance + position_value\n",
    "                    equity_curve.append(net_worth)\n",
    "                    rewards.append(0)\n",
    "            else:\n",
    "                if action == 1:  # HOLD LONG\n",
    "                    position_value = number_of_units_in_position*current_adj_close\n",
    "                    net_worth = balance + position_value\n",
    "                    equity_curve.append(net_worth)\n",
    "                    try:\n",
    "                        if metric == \"absolute\":\n",
    "                            rewards.append(equity_curve[-1] - equity_curve[-2])\n",
    "                        else:\n",
    "                            rewards.append((equity_curve[-1] - equity_curve[-2]) / equity_curve[-2])\n",
    "                    except:\n",
    "                        rewards.append(0)\n",
    "                else:  # CLOSE LONG\n",
    "                    balance = balance + (number_of_units_in_position*current_adj_close)\n",
    "                    in_position = False\n",
    "                    position_value = 0.0\n",
    "                    number_of_units_in_position = 0\n",
    "                    net_worth = balance + position_value\n",
    "                    equity_curve.append(net_worth)\n",
    "                    rewards.append(0)\n",
    "\n",
    "            try:\n",
    "                next_q_all_states.append(next_qs[i][0])\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        arr_fit_X = np.empty(shape=(0,len(features)*state_lookback)+1)\n",
    "        arr_fit_Y = np.empty(shape=(0,len(all_actions)))\n",
    "        for state, action, reward, cq, nq in zip(states, actions_history, rewards, current_q_all_states, next_q_all_states):\n",
    "            target = ((1. - alpha) * cq) + alpha * (reward + gamma * nq)\n",
    "            arr_fit_X = np.vstack((arr_fit_X,np.r_[state, action]))\n",
    "            arr_fit_Y = np.vstack((arr_fit_Y,np.array([target]).reshape(-1,1)))\n",
    "        model.fit(arr_fit_X,arr_fit_Y,epochs=30, verbose=0)\n",
    "        episode_return = equity_curve[-1]/equity_curve[0]-1\n",
    "        print(f\"Episode Number: {ii+1}, Total return of episode: {episode_return}\")\n",
    "        if plot:\n",
    "            plot_performance(train_data, prices, features, actions_history, equity_curve)\n",
    "\n",
    "        if episode_return>best_episode_return:\n",
    "            weights_best_performing = model.get_weights()\n",
    "            best_episode_return = episode_return\n",
    "\n",
    "        returns_vs_episodes.append(episode_return)\n",
    "\n",
    "    return model, returns_vs_episodes, weights_best_performing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_of_random_samples = 10\n",
    "model, returns_vs_episodes, weights = train_q_learning(train_df, state_lookback, model, alpha, epsilon, gamma, episodes, all_actions, metric, features, number_of_random_samples, plot=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, returns_vs_episodes, weights = train_q_learning(train_df, state_lookback, model, alpha, epsilon, gamma, episodes, all_actions, metric, features,plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = [\n",
    "    {\"feature\": \"Close_as_a_feature\", \"lookback\": 0},\n",
    "    {\"feature\": \"diff_of_close\", \"lookback\": 1},\n",
    "]\n",
    "\n",
    "#Experiment params\n",
    "ticker = 'sinx'#'NIFc1'\n",
    "tune = False\n",
    "train_percent = 0.8\n",
    "state_lookback = 1\n",
    "num_dense_layers = 2\n",
    "num_dense_layers_by_num_features = 2\n",
    "alpha = 0.5\n",
    "epsilon = 0.1\n",
    "gamma = 0.1\n",
    "episodes = 100\n",
    "metric = \"percent\"\n",
    "\n",
    "############################################################################################################################################\n",
    "\n",
    "#Get data\n",
    "df = get_stock_data(ticker)\n",
    "save[\"features\"] = features\n",
    "\n",
    "df = add_features(df, features, state_lookback, 0.8)\n",
    "train_df = df.iloc[:int(0.8 * len(df)), :]\n",
    "test_df = df.iloc[int(0.8 * len(df)):, :]\n",
    "\n",
    "\n",
    "########################## Changes made here ##################################\n",
    "all_actions = {0: 'percentage_invested_in_equity'}\n",
    "###############################################################################\n",
    "\n",
    "model = get_model(len(features)*state_lookback, len(all_actions), num_dense_layers, len(features)*state_lookback*num_dense_layers_by_num_features)\n",
    "# visualizer(model, format='png', view=True)\n",
    "\n",
    "model, returns_vs_episodes, weights = train_q_learning(train_df, state_lookback, model, alpha, epsilon, gamma, episodes, all_actions, metric, features,plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = [\n",
    "    {\"feature\": \"Close_as_a_feature\", \"lookback\": 0},\n",
    "    {\"feature\": \"diff_of_close\", \"lookback\": 1},\n",
    "]\n",
    "\n",
    "#Experiment params\n",
    "ticker = 'sinx'#'NIFc1'\n",
    "tune = False\n",
    "train_percent = 0.8\n",
    "state_lookback = 1\n",
    "num_dense_layers = 2\n",
    "num_dense_layers_by_num_features = 2\n",
    "alpha = 0.5\n",
    "epsilon = 0.1\n",
    "gamma = 0.1\n",
    "episodes = 100\n",
    "metric = \"percent\"\n",
    "\n",
    "############################################################################################################################################\n",
    "\n",
    "#Get data\n",
    "df = get_stock_data(ticker)\n",
    "save[\"features\"] = features\n",
    "\n",
    "df = add_features(df, features, state_lookback, 0.8)\n",
    "train_df = df.iloc[:int(0.8 * len(df)), :]\n",
    "test_df = df.iloc[int(0.8 * len(df)):, :]\n",
    "\n",
    "\n",
    "########################## Changes made here ##################################\n",
    "all_actions = {0: 'percentage_invested_in_equity'}\n",
    "###############################################################################\n",
    "\n",
    "model = get_model(len(features)*state_lookback, len(all_actions), num_dense_layers, len(features)*state_lookback*num_dense_layers_by_num_features)\n",
    "# visualizer(model, format='png', view=True)\n",
    "\n",
    "model, returns_vs_episodes, weights = train_q_learning(train_df, state_lookback, model, alpha, epsilon, gamma, episodes, all_actions, metric, features,plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}